{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool information: rev_module and PM Counters etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import PyUber\n",
    "from datetime import datetime, timedelta, date\n",
    "import glob, time\n",
    "import os\n",
    "    \n",
    "def convert_to_date(df, column1='MEAS_SET_DATA_COLLECT_DATE', column2='LOT_DATA_COLLECT_DATE', \\\n",
    "                    column3='CURRENT_MOVEIN_DATE', column4='END_DATE'):\n",
    "    if column1 in df.columns:\n",
    "        df[column1] = pd.to_datetime(df[column1])\n",
    "    if column2 in df.columns:\n",
    "        df[column2] = pd.to_datetime(df[column2])\n",
    "    if column3 in df.columns:\n",
    "        df[column3] = pd.to_datetime(df[column3])\n",
    "    if column4 in df.columns:\n",
    "        df[column4] = pd.to_datetime(df[column4])\n",
    "    return df\n",
    "\n",
    "def SQL_DataFrame(sql, source='D1D_PROD_XEUS'):\n",
    "    conn = PyUber.connect(source)\n",
    "    df = pd.read_sql(sql, conn)\n",
    "    return df\n",
    "\n",
    "def get90d(ss, datestr): \n",
    "    end = pd.Timestamp(datestr) + timedelta(days=1)\n",
    "    start = end - timedelta(days=90)\n",
    "    try:\n",
    "        ss = ss[(ss['LOT_DATA_COLLECT_DATE'] >= start) & (ss['LOT_DATA_COLLECT_DATE'] < end)]\n",
    "    except:\n",
    "        ss = convert_to_date(ss)\n",
    "        ss = ss[(ss['LOT_DATA_COLLECT_DATE'] >= start) & (ss['LOT_DATA_COLLECT_DATE'] < end)]\n",
    "    return ss\n",
    "\n",
    "sql=\"\"\"\n",
    "SELECT  DISTINCT \n",
    "          a1.entity AS entity\n",
    "         ,a5.value AS chart_value\n",
    "         ,To_Char(a0.data_collection_time,'yyyy-mm-dd hh24:mi:ss') AS lot_data_collect_date\n",
    "         ,a3.measurement_set_name AS measurement_set_name\n",
    "         ,To_Char(a3.data_collection_time,'yyyy-mm-dd hh24:mi:ss') AS meas_set_data_collect_date\n",
    "         ,a2.monitor_type AS monitor_type\n",
    "         ,a3.parameter_class AS parameter_class\n",
    "         ,a2.monitor_set_name AS monitor_set_name\n",
    "         ,a0.lotoperkey AS lotoperkey\n",
    "         ,a5.incontrol_flag AS incontrol_flag\n",
    "         ,a5.standard_flag AS chart_pt_standard_flag\n",
    "         ,a10.centerline AS centerline\n",
    "         ,a10.lo_control_lmt AS lo_control_lmt\n",
    "         ,a10.up_control_lmt AS up_control_lmt\n",
    "         ,a5.chart_type AS chart_type\n",
    "         ,a5.spc_chart_subset AS spc_chart_subset\n",
    "         ,a2.test_name AS test_name\n",
    "         ,a3.parameter_header AS parameter_header\n",
    "         ,a2.module AS module\n",
    "FROM \n",
    "P_SPC_MEASUREMENT_SET a3\n",
    "INNER JOIN P_SPC_SESSION a2 ON a2.spcs_id = a3.spcs_id\n",
    "LEFT JOIN P_SPC_LOT a0 ON a0.spcs_id = a2.spcs_id\n",
    "INNER JOIN P_SPC_ENTITY a1 ON a2.spcs_id = a1.spcs_id AND a1.entity_sequence=1\n",
    "LEFT JOIN P_SPC_CHART_POINT a5 ON a5.spcs_id = a3.spcs_id AND a5.measurement_set_name = a3.measurement_set_name\n",
    "LEFT JOIN P_SPC_CHART_LIMIT a10 ON a10.chart_id = a5.chart_id AND a10.limit_id = a5.limit_id\n",
    "WHERE\n",
    "              (a1.entity LIKE 'LAT%' \n",
    "              OR a1.entity LIKE 'PAT%')\n",
    " AND      a5.value Is Not Null  \n",
    " AND      a3.data_collection_time >= TRUNC(SYSDATE) - {} \n",
    " AND      a3.data_collection_time <= TRUNC(SYSDATE) - {} \n",
    " AND      a2.monitor_type = 'TOOL MONITOR' \n",
    " AND      a3.parameter_class = 'DEFECT_PARTICLE' \n",
    " AND      a5.spc_chart_subset = 'PARTICLE_SIZE=TOTAL_ADDERS'\n",
    "\"\"\"\n",
    "\n",
    "sql2= '''SELECT \n",
    "          e.entity AS entity\n",
    "         ,ea.attribute_value AS attribute_value\n",
    "         ,e.ceid AS ceid\n",
    "         ,ea.attribute_name AS attribute_name\n",
    "         ,e.rev_module AS rev_module\n",
    "FROM \n",
    "F_ENTITY e\n",
    "LEFT JOIN F_ENTITYATTRIBUTE ea ON ea.entity = e.entity AND ea.history_deleted_flag='N'\n",
    "WHERE\n",
    "              (e.entity Like 'PAT%' \n",
    "              OR e.entity Like 'LAT%')\n",
    " AND      ea.attribute_name Like 'PM_Counter' \n",
    "ORDER BY\n",
    "           1 Asc'''\n",
    "\n",
    "sql2= '''SELECT \n",
    "          e.entity AS entity\n",
    "         ,ea.attribute_value AS attribute_value\n",
    "         ,e.ceid AS ceid\n",
    "         ,ea.attribute_name AS attribute_name\n",
    "         ,e.rev_module AS rev_module\n",
    "FROM \n",
    "F_ENTITY e\n",
    "LEFT JOIN F_ENTITYATTRIBUTE ea ON ea.entity = e.entity AND ea.history_deleted_flag='N'\n",
    "WHERE\n",
    "              (e.entity Like 'LAT%' \n",
    "              OR e.entity Like 'PAT%'\n",
    "              OR e.entity Like 'REX%')\n",
    " AND      (ea.attribute_name Like 'PM_Counter' \n",
    "             OR ea.attribute_name Like 'Hit%Counter')\n",
    "ORDER BY\n",
    "           1 Asc'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_r = SQL_DataFrame(sql2)\n",
    "tool_r['ATTRIBUTE_VALUE'] = tool_r['ATTRIBUTE_VALUE'].astype(int)\n",
    "tools = pd.pivot_table(tool_r, values = 'ATTRIBUTE_VALUE', index = ['REV_MODULE', 'CEID' ,'ENTITY'], columns = 'ATTRIBUTE_NAME')\n",
    "tools = tools.reset_index()\n",
    "#tools[tools['ENTITY'] == 'LATXX']['REV_MODULE'].values[0]\n",
    "\n",
    "camp = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>ATTRIBUTE_VALUE</th>\n",
       "      <th>CEID</th>\n",
       "      <th>ATTRIBUTE_NAME</th>\n",
       "      <th>REV_MODULE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAT01_PM1</td>\n",
       "      <td>0</td>\n",
       "      <td>LATne</td>\n",
       "      <td>PMGCounter</td>\n",
       "      <td>FE  PAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAT01_PM1</td>\n",
       "      <td>1132</td>\n",
       "      <td>LATne</td>\n",
       "      <td>PMACounter</td>\n",
       "      <td>FE  PAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAT01_PM1</td>\n",
       "      <td>0</td>\n",
       "      <td>LATne</td>\n",
       "      <td>PMECounter</td>\n",
       "      <td>FE  PAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAT01_PM1</td>\n",
       "      <td>77064</td>\n",
       "      <td>LATne</td>\n",
       "      <td>PMDCounter</td>\n",
       "      <td>FE  PAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAT01_PM1</td>\n",
       "      <td>51538</td>\n",
       "      <td>LATne</td>\n",
       "      <td>PMCCounter</td>\n",
       "      <td>FE  PAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ENTITY  ATTRIBUTE_VALUE   CEID ATTRIBUTE_NAME REV_MODULE\n",
       "0  LAT01_PM1                0  LATne     PMGCounter    FE  PAT\n",
       "1  LAT01_PM1             1132  LATne     PMACounter    FE  PAT\n",
       "2  LAT01_PM1                0  LATne     PMECounter    FE  PAT\n",
       "3  LAT01_PM1            77064  LATne     PMDCounter    FE  PAT\n",
       "4  LAT01_PM1            51538  LATne     PMCCounter    FE  PAT"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have tool_r\n",
      "done in:  424.2910952568054\n"
     ]
    }
   ],
   "source": [
    "#pasts = [210,  270, 300, 330, 360, 390, 420, 450]\n",
    "pasts = [0]\n",
    "\n",
    "start =  time.time()\n",
    "\n",
    "try:\n",
    "    assert len(tool_r)>0\n",
    "    print('already have tool_r')\n",
    "except:\n",
    "    tool_r = SQL_DataFrame(sql2)\n",
    "    tool_r['ATTRIBUTE_VALUE'] = tool_r['ATTRIBUTE_VALUE'].astype(int)\n",
    "    tools = pd.pivot_table(tool_r, values = 'ATTRIBUTE_VALUE', index = ['REV_MODULE', 'CEID' ,'ENTITY'], columns = 'ATTRIBUTE_NAME')\n",
    "    tools = tools.reset_index()\n",
    "    tools.set_index(['ENTITY'], inplace = True)\n",
    "\n",
    "# Collect long term data \n",
    "for past in pasts:\n",
    "    ss = SQL_DataFrame(sql.format(str(past+600), str(past)))\n",
    "\n",
    "    camp = os.getcwd()\n",
    "\n",
    "    dstr = ss['LOT_DATA_COLLECT_DATE'].max()[:10]\n",
    "    dstr\n",
    "    fname = 'LAT.SPC.defect.' + dstr + '.csv'\n",
    "    fname\n",
    "    ss.to_csv(fname, index=False)\n",
    "    \n",
    "\n",
    "done1 = time.time()\n",
    "print('done in: ', done1-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.set_index(['ENTITY'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ATTRIBUTE_NAME</th>\n",
       "      <th>REV_MODULE</th>\n",
       "      <th>CEID</th>\n",
       "      <th>HitAlESCounter</th>\n",
       "      <th>HitAlGECounter</th>\n",
       "      <th>HitCEWaferCounter</th>\n",
       "      <th>HitChuckLifeCounter</th>\n",
       "      <th>HitClean1Counter</th>\n",
       "      <th>HitClean2Counter</th>\n",
       "      <th>HitClean3Counter</th>\n",
       "      <th>HitClean4Counter</th>\n",
       "      <th>...</th>\n",
       "      <th>HitTMPCounter</th>\n",
       "      <th>HitV1Counter</th>\n",
       "      <th>HitV2Counter</th>\n",
       "      <th>PMACounter</th>\n",
       "      <th>PMBCounter</th>\n",
       "      <th>PMCCounter</th>\n",
       "      <th>PMDCounter</th>\n",
       "      <th>PMECounter</th>\n",
       "      <th>PMFCounter</th>\n",
       "      <th>PMGCounter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTITY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REX415_EU4</th>\n",
       "      <td>BE  MM3</td>\n",
       "      <td>MM3ck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>17004.0</td>\n",
       "      <td>117443.0</td>\n",
       "      <td>117443.0</td>\n",
       "      <td>...</td>\n",
       "      <td>131668.0</td>\n",
       "      <td>117341.0</td>\n",
       "      <td>117341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REX405_EU1</th>\n",
       "      <td>BE  R3X</td>\n",
       "      <td>R3Xcb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>6566.0</td>\n",
       "      <td>6566.0</td>\n",
       "      <td>238771.0</td>\n",
       "      <td>...</td>\n",
       "      <td>173921.0</td>\n",
       "      <td>584497.0</td>\n",
       "      <td>584497.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REX401_EU2</th>\n",
       "      <td>BE  R3X</td>\n",
       "      <td>R3Xch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2913.0</td>\n",
       "      <td>24418.0</td>\n",
       "      <td>91829.0</td>\n",
       "      <td>265495.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96642.0</td>\n",
       "      <td>262786.0</td>\n",
       "      <td>262786.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REX406_EU1</th>\n",
       "      <td>BE  R3X</td>\n",
       "      <td>R3Xch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>4133.0</td>\n",
       "      <td>10016.0</td>\n",
       "      <td>193451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18214.0</td>\n",
       "      <td>43434.0</td>\n",
       "      <td>43434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REX406_EU2</th>\n",
       "      <td>BE  R3X</td>\n",
       "      <td>R3Xch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5421.0</td>\n",
       "      <td>33117.0</td>\n",
       "      <td>33245.0</td>\n",
       "      <td>206135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35414.0</td>\n",
       "      <td>56943.0</td>\n",
       "      <td>56943.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ATTRIBUTE_NAME REV_MODULE   CEID  HitAlESCounter  HitAlGECounter  \\\n",
       "ENTITY                                                             \n",
       "REX415_EU4        BE  MM3  MM3ck             0.0             0.0   \n",
       "REX405_EU1        BE  R3X  R3Xcb             0.0        297252.0   \n",
       "REX401_EU2        BE  R3X  R3Xch             0.0             0.0   \n",
       "REX406_EU1        BE  R3X  R3Xch             0.0             0.0   \n",
       "REX406_EU2        BE  R3X  R3Xch             0.0             0.0   \n",
       "\n",
       "ATTRIBUTE_NAME  HitCEWaferCounter  HitChuckLifeCounter  HitClean1Counter  \\\n",
       "ENTITY                                                                     \n",
       "REX415_EU4                    0.0                  0.0            5625.0   \n",
       "REX405_EU1                    0.0                  0.0             609.0   \n",
       "REX401_EU2                    0.0                  0.0            2913.0   \n",
       "REX406_EU1                    5.0                  0.0            4008.0   \n",
       "REX406_EU2                    0.0                  0.0            5421.0   \n",
       "\n",
       "ATTRIBUTE_NAME  HitClean2Counter  HitClean3Counter  HitClean4Counter  ...  \\\n",
       "ENTITY                                                                ...   \n",
       "REX415_EU4               17004.0          117443.0          117443.0  ...   \n",
       "REX405_EU1                6566.0            6566.0          238771.0  ...   \n",
       "REX401_EU2               24418.0           91829.0          265495.0  ...   \n",
       "REX406_EU1                4133.0           10016.0          193451.0  ...   \n",
       "REX406_EU2               33117.0           33245.0          206135.0  ...   \n",
       "\n",
       "ATTRIBUTE_NAME  HitTMPCounter  HitV1Counter  HitV2Counter  PMACounter  \\\n",
       "ENTITY                                                                  \n",
       "REX415_EU4           131668.0      117341.0      117341.0         NaN   \n",
       "REX405_EU1           173921.0      584497.0      584497.0         NaN   \n",
       "REX401_EU2            96642.0      262786.0      262786.0         NaN   \n",
       "REX406_EU1            18214.0       43434.0       43434.0         NaN   \n",
       "REX406_EU2            35414.0       56943.0       56943.0         NaN   \n",
       "\n",
       "ATTRIBUTE_NAME  PMBCounter  PMCCounter  PMDCounter  PMECounter  PMFCounter  \\\n",
       "ENTITY                                                                       \n",
       "REX415_EU4             NaN         NaN         NaN         NaN         NaN   \n",
       "REX405_EU1             NaN         NaN         NaN         NaN         NaN   \n",
       "REX401_EU2             NaN         NaN         NaN         NaN         NaN   \n",
       "REX406_EU1             NaN         NaN         NaN         NaN         NaN   \n",
       "REX406_EU2             NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ATTRIBUTE_NAME  PMGCounter  \n",
       "ENTITY                      \n",
       "REX415_EU4             NaN  \n",
       "REX405_EU1             NaN  \n",
       "REX401_EU2             NaN  \n",
       "REX406_EU1             NaN  \n",
       "REX406_EU2             NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FE  PAT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.loc['LAT01_PM2']['REV_MODULE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cleaned, smoothed surfscan tables and plot\n",
    "60 days, 20 points \n",
    "\n",
    "time ends at last spc data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f467e194e279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mwant_figs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mwant_figs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;31m#do plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;31m# PLOT the smoothed data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1330\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sta=pd.DataFrame()\n",
    "st=[0]\n",
    "csvs = glob.glob('training_data/LAT*.csv')\n",
    "csvs = ['training_data/LATREX.SPC.defect.2021-04-22.csv']\n",
    "csvs.reverse()\n",
    "\n",
    "existing_dates = []\n",
    "for csv in csvs:\n",
    "    d = csv.split('.')[-2]\n",
    "    existing_dates.append(d)\n",
    "\n",
    "\n",
    "for fnode in csvs:\n",
    "\n",
    "\n",
    "    dstr = fnode.split('.')[-2]\n",
    "    ss=pd.read_csv(fnode)\n",
    "    entities = ss.ENTITY.unique()\n",
    "    \n",
    "    taa = ss[ss['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "    taa = pd.merge(taa, tools, on='ENTITY')\n",
    "    taa=taa[['REV_MODULE', 'CHART_VALUE']]\n",
    "    taa=taa.rename(columns={'REV_MODULE': 'module', 'CHART_VALUE': 'TA'})\n",
    "    taac = taa[taa.groupby('module').TA.transform(lambda x: stats.zscore(x)<0.5)]\n",
    "    baselines = taac.groupby('module').mean()\n",
    "    \n",
    "    for entity in entities:\n",
    "        #if len(st)==20 : break\n",
    "            \n",
    "        #entity=entities[0]\n",
    "        try:\n",
    "            fname = tools.loc[entity]['REV_MODULE']+'.TA.'+entity+'.'+dstr\n",
    "            baseline = baselines.loc[tools.loc[entity]['REV_MODULE']].values\n",
    "        except:\n",
    "            fname = 'NONE.TA.'+entity+'.'+dstr\n",
    "            baseline = baselines['TA'].mean()\n",
    "        sst = ss[ss['ENTITY']==entity]\n",
    "        st = sst[sst['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "\n",
    "        st=st[['LOT_DATA_COLLECT_DATE', 'CHART_VALUE']]\n",
    "        st=st.rename(columns={'LOT_DATA_COLLECT_DATE': 't', 'CHART_VALUE': fname})\n",
    "        st.index = pd.to_datetime(st.t)\n",
    "        st.drop(['t'], axis=1, inplace = True)\n",
    "        if len(st)<20: continue # need enough data to interpolate properly\n",
    "        st=st.sort_index()\n",
    "        st=st.resample('3D').mean()\n",
    "        try:\n",
    "            st=st.interpolate(method='spline', order=2)\n",
    "            st[st<0] = 0\n",
    "        except:\n",
    "            continue\n",
    "        #st=np.log(st+1)\n",
    "        st = st[len(st)-20:]\n",
    "        if len(st)<20: continue #sometimes data doesn't extend back 60 days\n",
    "        #print(fname+' len: ', len(st))\n",
    "        \n",
    "        st = st/baseline\n",
    "        \n",
    "        want_figs = True\n",
    "        if ((len(st)==20) & (st.mean() < np.inf) & want_figs) : #do plot\n",
    "            # PLOT the smoothed data\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "            #ax = plt.subplot(111)\n",
    "            x = np.linspace(-len(st)+1,0,len(st)).reshape(-1,1)*3\n",
    "            ax.plot(x,st.values, 'o-')\n",
    "            ax.legend([entity+': '+dstr])\n",
    "            \n",
    "            # PLOT spline\n",
    "            try: \n",
    "                xn = np.linspace(x[0], x[-1], 100)\n",
    "                non_fliers = st.values.astype(float)<4\n",
    "                yp = st[non_fliers]\n",
    "                xp = x[non_fliers]\n",
    "                y_BSpline = interpolate.UnivariateSpline(xp,yp,s=20.)\n",
    "                yn = y_BSpline(xn)\n",
    "                ax.plot(xn, yn, '-')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            ax.set_xlabel('day')\n",
    "            ax.set_ylabel('TA')\n",
    "            ax.set_xticks([-60,-30,0])\n",
    "            plt.ylim([-0.1, 4])\n",
    "            \n",
    "            fig.savefig('figs/'+fname+'.png')\n",
    "            plt.close()\n",
    "            #break\n",
    "\n",
    "        #if len(st)==20 : break\n",
    "        st = st.reset_index().T.drop('t')\n",
    "        if sta.empty: sta=st\n",
    "        else: sta = sta.append(st)\n",
    "        #break\n",
    "    \n",
    "    #break\n",
    "\n",
    "print('seconds: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>CHART_VALUE</th>\n",
       "      <th>LOT_DATA_COLLECT_DATE</th>\n",
       "      <th>MEASUREMENT_SET_NAME</th>\n",
       "      <th>MEAS_SET_DATA_COLLECT_DATE</th>\n",
       "      <th>MONITOR_TYPE</th>\n",
       "      <th>PARAMETER_CLASS</th>\n",
       "      <th>MONITOR_SET_NAME</th>\n",
       "      <th>LOTOPERKEY</th>\n",
       "      <th>INCONTROL_FLAG</th>\n",
       "      <th>CHART_PT_STANDARD_FLAG</th>\n",
       "      <th>CENTERLINE</th>\n",
       "      <th>LO_CONTROL_LMT</th>\n",
       "      <th>UP_CONTROL_LMT</th>\n",
       "      <th>CHART_TYPE</th>\n",
       "      <th>SPC_CHART_SUBSET</th>\n",
       "      <th>TEST_NAME</th>\n",
       "      <th>PARAMETER_HEADER</th>\n",
       "      <th>MODULE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAT426_PM3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9/17/2019 17:45</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.DER</td>\n",
       "      <td>9/17/2019 17:45</td>\n",
       "      <td>TOOL MONITOR</td>\n",
       "      <td>DEFECT_PARTICLE</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.MON</td>\n",
       "      <td>1847754675</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>X-BAR</td>\n",
       "      <td>PARTICLE_SIZE=TOTAL_ADDERS</td>\n",
       "      <td>4LATTINNTSSPS</td>\n",
       "      <td>PARTICLE_SIZE</td>\n",
       "      <td>LAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAT426_PM3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9/26/2019 09:09</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.DER</td>\n",
       "      <td>9/26/2019 09:09</td>\n",
       "      <td>TOOL MONITOR</td>\n",
       "      <td>DEFECT_PARTICLE</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.MON</td>\n",
       "      <td>1864650392</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>X-BAR</td>\n",
       "      <td>PARTICLE_SIZE=TOTAL_ADDERS</td>\n",
       "      <td>4LATTINNTSSPS</td>\n",
       "      <td>PARTICLE_SIZE</td>\n",
       "      <td>LAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAT408_PM5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/28/2020 11:31</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.DER</td>\n",
       "      <td>1/28/2020 11:31</td>\n",
       "      <td>TOOL MONITOR</td>\n",
       "      <td>DEFECT_PARTICLE</td>\n",
       "      <td>LAT.DSA_TIN_PST.74.MON</td>\n",
       "      <td>2053656495</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>X-BAR</td>\n",
       "      <td>PARTICLE_SIZE=TOTAL_ADDERS</td>\n",
       "      <td>4LATTINNTSSPS</td>\n",
       "      <td>PARTICLE_SIZE</td>\n",
       "      <td>LAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAT416_PM1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/29/2020 05:08</td>\n",
       "      <td>LAT.DSA_PST.74.DER</td>\n",
       "      <td>1/29/2020 05:08</td>\n",
       "      <td>TOOL MONITOR</td>\n",
       "      <td>DEFECT_PARTICLE</td>\n",
       "      <td>LAT.DSA_PST.74.MON</td>\n",
       "      <td>2053656495</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>X-BAR</td>\n",
       "      <td>PARTICLE_SIZE=TOTAL_ADDERS</td>\n",
       "      <td>4LATNTSSPS</td>\n",
       "      <td>PARTICLE_SIZE</td>\n",
       "      <td>LAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAT430_PM4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/18/2020 21:06</td>\n",
       "      <td>PATBE.DSA_PST.76.DER</td>\n",
       "      <td>1/18/2020 21:06</td>\n",
       "      <td>TOOL MONITOR</td>\n",
       "      <td>DEFECT_PARTICLE</td>\n",
       "      <td>PATBE.DSA_PST.76.MON</td>\n",
       "      <td>2053972317</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>X-BAR</td>\n",
       "      <td>PARTICLE_SIZE=TOTAL_ADDERS</td>\n",
       "      <td>6PATBESSPST</td>\n",
       "      <td>PARTICLE_SIZE</td>\n",
       "      <td>PAT BE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENTITY  CHART_VALUE LOT_DATA_COLLECT_DATE    MEASUREMENT_SET_NAME  \\\n",
       "0  LAT426_PM3          0.0       9/17/2019 17:45  LAT.DSA_TIN_PST.74.DER   \n",
       "1  LAT426_PM3          0.0       9/26/2019 09:09  LAT.DSA_TIN_PST.74.DER   \n",
       "2  PAT408_PM5          0.0       1/28/2020 11:31  LAT.DSA_TIN_PST.74.DER   \n",
       "3  LAT416_PM1          0.0       1/29/2020 05:08      LAT.DSA_PST.74.DER   \n",
       "4  PAT430_PM4          0.0       1/18/2020 21:06    PATBE.DSA_PST.76.DER   \n",
       "\n",
       "  MEAS_SET_DATA_COLLECT_DATE  MONITOR_TYPE  PARAMETER_CLASS  \\\n",
       "0            9/17/2019 17:45  TOOL MONITOR  DEFECT_PARTICLE   \n",
       "1            9/26/2019 09:09  TOOL MONITOR  DEFECT_PARTICLE   \n",
       "2            1/28/2020 11:31  TOOL MONITOR  DEFECT_PARTICLE   \n",
       "3            1/29/2020 05:08  TOOL MONITOR  DEFECT_PARTICLE   \n",
       "4            1/18/2020 21:06  TOOL MONITOR  DEFECT_PARTICLE   \n",
       "\n",
       "         MONITOR_SET_NAME  LOTOPERKEY INCONTROL_FLAG CHART_PT_STANDARD_FLAG  \\\n",
       "0  LAT.DSA_TIN_PST.74.MON  1847754675              N                      N   \n",
       "1  LAT.DSA_TIN_PST.74.MON  1864650392              N                      N   \n",
       "2  LAT.DSA_TIN_PST.74.MON  2053656495              Y                      Y   \n",
       "3      LAT.DSA_PST.74.MON  2053656495              Y                      Y   \n",
       "4    PATBE.DSA_PST.76.MON  2053972317              Y                      Y   \n",
       "\n",
       "   CENTERLINE  LO_CONTROL_LMT  UP_CONTROL_LMT CHART_TYPE  \\\n",
       "0        1.01             0.0             3.6      X-BAR   \n",
       "1        1.01             0.0             3.6      X-BAR   \n",
       "2        1.01             0.0             3.6      X-BAR   \n",
       "3        1.01             0.0             3.2      X-BAR   \n",
       "4        0.50             0.0             3.6      X-BAR   \n",
       "\n",
       "             SPC_CHART_SUBSET      TEST_NAME PARAMETER_HEADER  MODULE  \n",
       "0  PARTICLE_SIZE=TOTAL_ADDERS  4LATTINNTSSPS    PARTICLE_SIZE     LAT  \n",
       "1  PARTICLE_SIZE=TOTAL_ADDERS  4LATTINNTSSPS    PARTICLE_SIZE     LAT  \n",
       "2  PARTICLE_SIZE=TOTAL_ADDERS  4LATTINNTSSPS    PARTICLE_SIZE     LAT  \n",
       "3  PARTICLE_SIZE=TOTAL_ADDERS     4LATNTSSPS    PARTICLE_SIZE     LAT  \n",
       "4  PARTICLE_SIZE=TOTAL_ADDERS    6PATBESSPST    PARTICLE_SIZE  PAT BE  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2rex= '''SELECT \n",
    "          e.entity AS entity\n",
    "         ,ea.attribute_value AS attribute_value\n",
    "         ,e.ceid AS ceid\n",
    "         ,ea.attribute_name AS attribute_name\n",
    "         ,e.rev_module AS rev_module\n",
    "FROM \n",
    "F_ENTITY e\n",
    "LEFT JOIN F_ENTITYATTRIBUTE ea ON ea.entity = e.entity AND ea.history_deleted_flag='N'\n",
    "WHERE\n",
    "    e.entity Like 'REX%' \n",
    "AND      ea.attribute_name Like 'Hit%Counter' \n",
    "\n",
    "ORDER BY\n",
    "           1 Asc'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_data/training_dates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a5c3aabf5a24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#             '2020-02-25']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtraining_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_data/training_dates.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0msnapdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\IntelLearn\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_data/training_dates.csv'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sta=pd.DataFrame()\n",
    "st=[0]\n",
    "\n",
    "ssb = pd.read_csv('training_data/LATREX.SPC.defect.2021-04-22.csv')\n",
    "\n",
    "# snapdates = ['2021-04-14', '2021-03-31', '2021-03-17', '2021-01-21', '2020-12-23', '2020-11-24', '2020-10-18', \\\n",
    "#             '2020-09-20', '2020-08-23', '2020-07-21', '2020-06-23', '2020-05-25', '2020-04-22', '2020-03-25', \\\n",
    "#             '2020-02-25']\n",
    "\n",
    "training_dates=pd.read_csv('training_data/training_dates.csv')\n",
    "snapdates = training_dates[training_dates['Module'] == 'LAT']['Date']\n",
    "\n",
    "# csvs = glob.glob('training_data/LAT*.csv')\n",
    "# csvs.reverse()\n",
    "\n",
    "#Get module/tool information\n",
    "tool_r = SQL_DataFrame(sql2)\n",
    "tool_r['ATTRIBUTE_VALUE'] = tool_r['ATTRIBUTE_VALUE'].astype(int)\n",
    "tools = pd.pivot_table(tool_r, values = 'ATTRIBUTE_VALUE', index = ['REV_MODULE', 'CEID' ,'ENTITY'], columns = 'ATTRIBUTE_NAME')\n",
    "tools = tools.reset_index()\n",
    "tools.set_index(['ENTITY'], inplace = True)\n",
    "\n",
    "#Calculate module baselines\n",
    "taa = ssb[ssb['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "taa = pd.merge(taa, tools, on='ENTITY')\n",
    "taa=taa[['REV_MODULE', 'CHART_VALUE']]\n",
    "taa=taa.rename(columns={'REV_MODULE': 'module', 'CHART_VALUE': 'TA'})\n",
    "taac = taa[taa.groupby('module').TA.transform(lambda x: stats.zscore(x)<0.5)]\n",
    "baselines = taac.groupby('module').mean()\n",
    "\n",
    "#existing_dates = []\n",
    "\n",
    "for dstr in snapdates:\n",
    "    ss = get90d(ssb, dstr)\n",
    "    entities = ss.ENTITY.unique()\n",
    "    \n",
    "#     taa = ss[ss['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "#     taa = pd.merge(taa, tools, on='ENTITY')\n",
    "#     taa=taa[['REV_MODULE', 'CHART_VALUE']]\n",
    "#     taa=taa.rename(columns={'REV_MODULE': 'module', 'CHART_VALUE': 'TA'})\n",
    "#     taac = taa[taa.groupby('module').TA.transform(lambda x: stats.zscore(x)<0.5)]\n",
    "#     baselines = taac.groupby('module').mean()\n",
    "    \n",
    "    for entity in entities:\n",
    "        #if len(st)==20 : break\n",
    "            \n",
    "        #entity=entities[0]\n",
    "        try:\n",
    "            fname = tools.loc[entity]['REV_MODULE']+'.TA.'+entity+'.'+dstr\n",
    "            baseline = baselines.loc[tools.loc[entity]['REV_MODULE']].values\n",
    "        except:\n",
    "            fname = 'NONE.TA.'+entity+'.'+dstr\n",
    "            baseline = baselines['TA'].mean()\n",
    "        sst = ss[ss['ENTITY']==entity]\n",
    "        st = sst[sst['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "\n",
    "        st=st[['LOT_DATA_COLLECT_DATE', 'CHART_VALUE']]\n",
    "        st=st.rename(columns={'LOT_DATA_COLLECT_DATE': 't', 'CHART_VALUE': fname})\n",
    "        st.index = pd.to_datetime(st.t)\n",
    "        st.drop(['t'], axis=1, inplace = True)\n",
    "        if len(st)<20: continue # need enough data to interpolate properly\n",
    "        st=st.sort_index()\n",
    "        st=st.resample('3D').mean()\n",
    "        try:\n",
    "            st=st.interpolate(method='spline', order=2)\n",
    "            st[st<0] = 0\n",
    "        except:\n",
    "            continue\n",
    "        #st=np.log(st+1)\n",
    "        st = st[len(st)-20:]\n",
    "        if len(st)<20: continue #sometimes data doesn't extend back 60 days\n",
    "        #print(fname+' len: ', len(st))\n",
    "        \n",
    "        st = st/baseline\n",
    "        \n",
    "        want_figs = False\n",
    "        if ((len(st)==20) & (st.mean() < np.inf)[0] & want_figs) : #do plot\n",
    "            # PLOT the smoothed data\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "            #ax = plt.subplot(111)\n",
    "            x = np.linspace(-len(st)+1,0,len(st)).reshape(-1,1)*3\n",
    "            ax.plot(x,st.values, 'o-')\n",
    "            ax.legend([entity+': '+dstr])\n",
    "            \n",
    "            # PLOT spline\n",
    "            try: \n",
    "                xn = np.linspace(x[0], x[-1], 100)\n",
    "                non_fliers = st.values.astype(float)<4\n",
    "                yp = st[non_fliers]\n",
    "                xp = x[non_fliers]\n",
    "                y_BSpline = interpolate.UnivariateSpline(xp,yp,s=20.)\n",
    "                yn = y_BSpline(xn)\n",
    "                ax.plot(xn, yn, '-')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            ax.set_xlabel('day')\n",
    "            ax.set_ylabel('TA')\n",
    "            ax.set_xticks([-60,-30,0])\n",
    "            plt.ylim([-0.1, 4])\n",
    "            \n",
    "            fig.savefig('figs/'+fname+'.png')\n",
    "            plt.close()\n",
    "            #break\n",
    "\n",
    "        #if len(st)==20 : break\n",
    "        st = st.reset_index().T.drop('t')\n",
    "        if sta.empty: sta=st\n",
    "        else: sta = sta.append(st)\n",
    "        #break\n",
    "    \n",
    "    #break\n",
    "\n",
    "print('seconds: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.to_csv('training_data/LATREX.SPC.defect.2021-04-22.sta.csv')\n",
    "baselines.to_csv('training_data/LATREX.baselines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(camp+'/figs/1trending')\n",
    "trending = pd.Series(glob.glob('*.png'), name = 'key').apply(lambda x: x.split('.png')[0])\n",
    "trending = pd.DataFrame(trending)\n",
    "trending['trending'] = 1\n",
    "\n",
    "os.chdir(camp+'/figs/2burst')\n",
    "burst = pd.Series(glob.glob('*.png'), name = 'key').apply(lambda x: x.split('.png')[0])\n",
    "burst = pd.DataFrame(burst)\n",
    "burst['burst'] = 1\n",
    "\n",
    "os.chdir(camp+'/figs/3elevated')\n",
    "elevated = pd.Series(glob.glob('*.png'), name = 'key').apply(lambda x: x.split('.png')[0])\n",
    "elevated = pd.DataFrame(elevated)\n",
    "elevated['elevated'] = 1\n",
    "\n",
    "os.chdir(camp+'/figs/4clean')\n",
    "clean = pd.Series(glob.glob('*.png'), name = 'key').apply(lambda x: x.split('.png')[0])\n",
    "clean = pd.DataFrame(clean)\n",
    "clean['clean'] = 1\n",
    "\n",
    "binned = pd.concat([trending, burst, elevated, clean]).fillna(0).set_index('key')\n",
    "\n",
    "os.chdir(camp)\n",
    "#trending.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned.to_csv('training_data/LATREX.binned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(camp+'/figs/dirty')\n",
    "dirtylist = glob.glob('*.png')\n",
    "os.chdir(camp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binned = {'trending': trending, 'burst': burst, 'elevated': elevated, 'clean': clean}\n",
    "keys = pd.concat([trending, burst, elevated, clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned=pd.DataFrame()\n",
    "binned['keys'] = keys\n",
    "binned['trending'] = binned['keys'].apply(lambda x: 1 if x in trending else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'DE-LAT-NVE.TA.LAT424_PM2.2020-03-25' in trending.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty.split('.png')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirtylist=pd.Series(dirtylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirtylist = dirtylist.apply(lambda x: x.split('.png')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirtylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sta['is_dirty'] =  pd.Series(sta.index).apply(lambda x: (x in dirtylist.values)*1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = sta.rename_axis('key')\n",
    "stay = pd.merge(sta, binned, on=['key'], how='inner')\n",
    "stay.to_csv('training_data/cleaned_charts_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned['trending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.to_csv('training_data/cleaned_charts_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sta.T[sta.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sta.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.linspace(x[0], x[-1]+1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fliers = stats.zscore(y.astype(float))<1\n",
    "yp = y[non_fliers]\n",
    "xp = x[non_fliers]\n",
    "y_BSpline = interpolate.UnivariateSpline(xp,yp,s=40.)\n",
    "y_new = y_BSpline(x_new)\n",
    "plt.plot(x_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = np.linspace(x[0], x[-1], 100)\n",
    "y_BSpline = interpolate.UnivariateSpline(x,st.values,s=40.)\n",
    "yn = y_BSpline(xn)\n",
    "plt.plot(xn, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "#ax = plt.subplot(111)\n",
    "x = np.linspace(-len(st)+1,0,len(st)).reshape(-1,1)*3\n",
    "ax.plot(x,st.values, 'o-')\n",
    "\n",
    "\n",
    "xn = np.linspace(x[0], x[-1], 100)\n",
    "y_BSpline = interpolate.UnivariateSpline(x,st.values,s=20.)\n",
    "yn = y_BSpline(xn)\n",
    "ax.plot(xn, yn, '-')\n",
    "\n",
    "ax.set_xlabel('date')\n",
    "ax.set_ylabel('TA')\n",
    "ax.set_xticks([-60,-30,0])\n",
    "ax.legend([entity+': '+dstr])\n",
    "plt.ylim([-0.1, 4])\n",
    "\n",
    "#fig.savefig('figs/'+fname+'.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-60,1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "taa = ss[ss['SPC_CHART_SUBSET'] == 'PARTICLE_SIZE=TOTAL_ADDERS']\n",
    "taa = pd.merge(taa, tools, on='ENTITY')\n",
    "taa=taa[['REV_MODULE', 'CHART_VALUE']]\n",
    "taa=taa.rename(columns={'REV_MODULE': 'module', 'CHART_VALUE': 'TA'})\n",
    "taac = taa[taa.groupby('module').TA.transform(lambda x: stats.zscore(x)<0.3)]\n",
    "baselines = taac.groupby('module').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st/baseline.loc['DE-LAT-TNC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.loc['DE-LAT-TNC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline['TA'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.loc[tools.loc[entity]['REV_MODULE']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = sta.loc['DE-PAT-XD.TA.PAT458_PM3.2021-02-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(st)==20 & (st.mean() < np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa=pd.read_csv('LAT.SPC.defect.2021-03-17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ssa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(df, column1='MEAS_SET_DATA_COLLECT_DATE', column2='LOT_DATA_COLLECT_DATE', \\\n",
    "                    column3='CURRENT_MOVEIN_DATE', column4='END_DATE'):\n",
    "    if column1 in df.columns:\n",
    "        df[column1] = pd.to_datetime(df[column1])\n",
    "    if column2 in df.columns:\n",
    "        df[column2] = pd.to_datetime(df[column2])\n",
    "    if column3 in df.columns:\n",
    "        df[column3] = pd.to_datetime(df[column3])\n",
    "    if column4 in df.columns:\n",
    "        df[column4] = pd.to_datetime(df[column4])\n",
    "    return df\n",
    "\n",
    "ssa=convert_to_date(ssa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa.sort_values(by=['MEAS_SET_DATA_COLLECT_DATE'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 9\n",
    "ss=ssa[(ss['MEAS_SET_DATA_COLLECT_DATE']<datetime.now() - timedelta(days=start)) & (ss['MEAS_SET_DATA_COLLECT_DATE']>datetime.now() - timedelta(days= (90+start)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for csv in csvs:\n",
    "    d = csv.split('.')[-2]\n",
    "    ds.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = pd.read_csv('LAT.SPC.defect.2021-03-17.csv')\n",
    "ss2 = pd.read_csv('LAT.SPC.defect.2021-03-16.csv')\n",
    "ss3 = pd.read_csv('LAT.SPC.defect.2021-04-22.csv')\n",
    "\n",
    "key_cols = ['ENTITY', 'CHART_VALUE', 'LOT_DATA_COLLECT_DATE',\\\n",
    "       'MEASUREMENT_SET_NAME', 'MEAS_SET_DATA_COLLECT_DATE', 'MONITOR_TYPE',\\\n",
    "       'PARAMETER_CLASS', 'MONITOR_SET_NAME', 'LOTOPERKEY', 'INCONTROL_FLAG',\\\n",
    "       'CHART_PT_STANDARD_FLAG', 'CENTERLINE', 'LO_CONTROL_LMT',\\\n",
    "       'UP_CONTROL_LMT', 'CHART_TYPE', 'SPC_CHART_SUBSET', 'TEST_NAME',\\\n",
    "       'PARAMETER_HEADER', 'MODULE']\n",
    "#key_cols = ['ENTITY', 'CHART_VALUE', 'LOT_DATA_COLLECT_DATE', 'SPC_CHART_SUBSET']\n",
    "LAT_ss = pd.merge(ss1, ss2, left_on=key_cols, right_on=key_cols, how='outer')\n",
    "LAT_ss = pd.merge(LAT_ss, ss3, left_on=key_cols, right_on=key_cols, how='outer')\n",
    "#LAT_ss.to_csv('LAT.SPC.defect.2021-04-22.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAT_ss.to_csv('training_data/LAT.SPC.defect.2021-04-22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_ss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_ss=convert_to_date(LAT_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ss1.LOT_DATA_COLLECT_DATE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LAT_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=pd.read_csv('training_data/LAT.SPC.defect.2021-04-22.csv')\n",
    "rex=pd.read_csv('training_data/REX.SPC.defect.2021-04-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latrex=pd.concat([lat, rex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latrex.to_csv('training_data/LATREX.SPC.defect.2021-04-22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=pd.read_csv('training_data/LAT.SPC.defect.2021-04-22.sta.csv')\n",
    "rex=pd.read_csv('training_data/REX.SPC.defect.2021-04-22.sta.csv')\n",
    "latrex=pd.concat([lat, rex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latrex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_ss = pd.concat([ss1, ss2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss3)==len(ss1)+len(ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LAT_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
